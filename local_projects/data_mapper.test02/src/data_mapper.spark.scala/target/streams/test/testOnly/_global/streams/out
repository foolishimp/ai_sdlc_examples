[debug] javaOptions: Vector(--add-opens=java.base/java.lang=ALL-UNNAMED, --add-opens=java.base/java.lang.invoke=ALL-UNNAMED, --add-opens=java.base/java.lang.reflect=ALL-UNNAMED, --add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.net=ALL-UNNAMED, --add-opens=java.base/java.nio=ALL-UNNAMED, --add-opens=java.base/java.util=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.base/sun.nio.cs=ALL-UNNAMED, --add-opens=java.base/sun.security.action=ALL-UNNAMED, --add-opens=java.base/sun.util.calendar=ALL-UNNAMED, --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED)
[debug] Forking tests - parallelism = false
[debug] Create a single-thread test executor
[debug] Runner for org.scalatest.tools.Framework produced 1 initial tasks for 1 tests.
[debug]   Running TaskDef(cdme.UATSpec, sbt.ForkMain$SubclassFingerscan@73ad2d6, false, [SuiteSelector])
[info] UATSpec:
[info] Feature: UAT-001: Schema Registry Setup
[info]   As a Data Engineer 
[info]   I want to register entity schemas in the registry 
[info]   So that I can validate data mappings against known schemas 
[info]   Scenario: User registers valid entities with physical bindings
[info]     Given a set of entity definitions with attributes and relationships 
[info]     And physical bindings for each entity 
[info]     When the user creates a schema registry 
[info]     Then the registry should be created successfully 
[info]     And all entities should be accessible 
[info]   Scenario: User queries for non-existent entity
[info]     Given a schema registry with registered entities 
[info]     When the user queries for an entity that doesn't exist 
[info]     Then the registry should return an error 
[info] Feature: UAT-002: Relationship Path Validation
[info]   As a Data Engineer 
[info]   I want to validate attribute paths including relationship traversals 
[info]   So that I can catch invalid references at compile time 
[info]   Scenario: User validates a correct relationship path
[info]     Given a schema registry with Order -> Customer relationship 
[info]     When the user validates path 'Order.customer.name' 
[info]     Then the validation should succeed 
[info]     And the final type should be String 
[info]     And the path should include the relationship traversal 
[info]   Scenario: User validates path with invalid relationship
[info]     Given a schema registry with defined relationships 
[info]     When the user validates a path with non-existent relationship 
[info]     Then the validation should fail 
[info]   Scenario: User validates path with invalid attribute
[info]     Given a schema registry with defined entities 
[info]     When the user validates a path with non-existent attribute 
[info]     Then the validation should fail 
[info] Feature: UAT-003: Simple Mapping Compilation
[info]   As a Data Engineer 
[info]   I want to compile mapping definitions into execution plans 
[info]   So that the system can execute data transformations 
[info]   Scenario: User compiles a simple entity-to-entity mapping
[info]     Given a schema registry with Order entity 
[info]     And a simple mapping that copies Order fields 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the execution plan should have correct mapping name 
[info]     And the plan should include both projections 
[info] Feature: UAT-004: Grain Safety Enforcement
[info]   As a Data Engineer 
[info]   I want the system to prevent grain coarsening without aggregation 
[info]   So that I don't accidentally lose data through improper transformations 
[info]   Scenario: User attempts grain coarsening without aggregation
[info]     Given a source at Atomic grain (order_id) 
[info]     And a target at Customer grain (customer_id) 
[info]     When the user attempts this transition without aggregation 
[info]     Then the validation should fail with a GrainSafetyError 
[info]   Scenario: User performs grain coarsening with proper aggregation
[info]     Given a source at Atomic grain (order_id) 
[info]     And a target at Customer grain (customer_id) 
[info]     When the user includes aggregation in the mapping 
[info]     Then the validation should succeed 
[info]   Scenario: User performs same-grain transformation
[info]     Given a source and target at the same Atomic grain 
[info]     When the user creates a mapping without aggregation 
[info]     Then the validation should succeed 
[info] Feature: UAT-005: Filter Morphism Definition
[info]   As a Data Engineer 
[info]   I want to define filter morphisms with SQL predicates 
[info]   So that I can filter data based on business rules 
[info]   Scenario: User creates a mapping with filter morphism
[info]     Given a schema registry with Order entity 
[info]     And a mapping with a filter for completed orders 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should include the filter morphism 
[info]     And the filter should have the correct predicate 
[info] Feature: UAT-006: Aggregation Mapping
[info]   As a Data Engineer 
[info]   I want to create aggregation mappings with SUM, COUNT, etc. 
[info]   So that I can summarize data at coarser grains 
[info]   Scenario: User creates order summary with aggregations
[info]     Given a schema registry with Order and CustomerOrderSummary entities 
[info]     And a mapping that aggregates orders by customer 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should have aggregation projections 
[info]     And SUM aggregation should be present 
[info]     And COUNT aggregation should be present 
[info] Feature: UAT-007: Clear Error Messages
[info]   As a Data Engineer 
[info]   I want to receive clear error messages when something goes wrong 
[info]   So that I can quickly identify and fix issues 
[info]   Scenario: User references non-existent source entity
[info]     Given a schema registry with known entities 
[info]     And a mapping referencing a non-existent entity 
[info]     When the user attempts to compile the mapping 
[info]     Then the compilation should fail 
[info]     And the error should have a descriptive error type 
[info]   Scenario: User uses invalid attribute path in projection
[info]     Given a schema registry with Order entity 
[info]     And a mapping with an invalid path in projections 
[info]     When the user attempts to compile the mapping 
[info]     Then the compilation should fail 
[info] Feature: UAT-008: Chained Morphisms
[info]   As a Data Engineer 
[info]   I want to chain multiple morphisms together 
[info]   So that I can build complex transformation pipelines 
[info]   Scenario: User creates pipeline with filter-filter-aggregate chain
[info]     Given a schema registry with Order and CustomerOrderSummary entities 
[info]     And a mapping with multiple chained morphisms 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should have 3 morphisms in order 
[info]     And each morphism should have correct name 
[info] Feature: UAT-009: Relationship Traversal in Projections
[info]   As a Data Engineer 
[info]   I want to include attributes from related entities in projections 
[info]   So that I can denormalize data through relationship traversal 
[info]   Scenario: User projects attribute from related entity
[info]     Given a schema registry with Order -> Customer relationship 
[info]     When the user validates a path traversing the relationship 
[info]     Then the path validation should succeed 
[info]     And the path should resolve to the Customer entity's attribute type 
[info]     And the traversal should include the customer relationship 
[info] Feature: UAT-010: Consistent Error Typing
[info]   As a Data Engineer 
[info]   I want errors to have consistent, machine-readable types 
[info]   So that I can build automation around error handling 
[info]   Scenario: Compilation error has correct error type
[info]     Given a compilation error 
[info]     When the error type is retrieved 
[info]     Then it should be in snake_case format 
[info]   Scenario: Grain safety error has correct error type
[info]     Given a grain safety error 
[info]     When the error type is retrieved 
[info]     Then it should be in snake_case format 
[info] Feature: UAT-011: Window Functions and Temporal Aggregations
[info]   As a Data Engineer 
[info]   I want to use window functions for running totals and rankings 
[info]   So that I can compute metrics that require ordered or partitioned context 
[info]   Scenario: User creates mapping with window function morphism
[info]     Given a schema registry with Order entity 
[info]     And a mapping with a WINDOW morphism for running total 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should include the window morphism 
[info]     And the window should have partition and order specification 
[info]   Scenario: User creates ranking window function
[info]     Given a schema registry with Order entity 
[info]     And a mapping for ranking orders within customer by amount 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the ranking projection should be present 
[info] Feature: UAT-012: Data Quality Validations
[info]   As a Data Engineer 
[info]   I want to define data quality validations in my mappings 
[info]   So that I can ensure data meets business requirements 
[info]   Scenario: User defines NOT NULL validation for required field
[info]     Given a schema registry with Order entity 
[info]     And a mapping with validation rules for non-null order_id 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should include the validation 
[info]   Scenario: User defines RANGE validation for numeric field
[info]     Given a schema registry with Order entity 
[info]     And a mapping with range validation for amount > 0 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should include the range validation 
[info]   Scenario: User defines PATTERN validation for string format
[info]     Given a schema registry with Order entity 
[info]     And a mapping with pattern validation for status 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And the plan should include the pattern validation 
[info] Feature: UAT-013: Performance with Large Datasets
[info]   As a Data Engineer 
[info]   I want to configure performance settings for large datasets 
[info]   So that I can process data efficiently at scale 
[info]   Scenario: User configures BATCH execution mode
[info]     Given an execution configuration 
[info]     When the configuration is used 
[info]     Then the execution mode should be BATCH 
[info]     And the error threshold should be 5% 
[info]     And the lineage mode should be KEY_DERIVABLE 
[info]   Scenario: User configures STREAM execution mode
[info]     Given a streaming execution configuration 
[info]     When the configuration is used 
[info]     Then the execution mode should be STREAM 
[info]     And the error threshold should be stricter at 1% 
[info]   Scenario: User configures output paths for partitioned writes
[info]     Given an output configuration 
[info]     When the configuration is validated 
[info]     Then the data path should support partition expressions 
[info]     And error path should be configured 
[info] Feature: UAT-014: Error Recovery and Retry Logic
[info]   As a Data Engineer 
[info]   I want to configure error thresholds and handling 
[info]   So that I can manage partial failures gracefully 
[info]   Scenario: User configures error threshold percentage
[info]     Given an execution configuration with 5% error threshold 
[info]     When the threshold is evaluated 
[info]     Then errors up to 5% should be tolerable 
[info]     And the threshold should be between 0 and 1 
[info]   Scenario: User configures strict zero-tolerance error threshold
[info]     Given an execution configuration with zero tolerance 
[info]     When the threshold is evaluated 
[info]     Then no errors should be tolerated 
[info]   Scenario: User creates CDME error with full context
[info]     Given a data validation failure 
[info]     When the error is examined 
[info]     Then it should have the source key for traceability 
[info]     And it should have the full morphism path 
[info]     And it should identify the failing rule 
[info]     And it should have a machine-readable error type 
[info]   Scenario: User creates DLQ (dead letter queue) error record
[info]     Given a type cast failure 
[info]     When the error is captured for DLQ 
[info]     Then it should contain the original value for debugging 
[info]     And it should show the type conversion attempted 
[info] Feature: UAT-015: Configuration Validation Edge Cases
[info]   As a Data Engineer 
[info]   I want configuration errors to be caught early 
[info]   So that I don't discover issues at runtime 
[info]   Scenario: User provides empty mapping name
[info]     Given a mapping configuration with empty name 
[info]     When the configuration is used 
[info]     Then the name should be empty string (validation at compile time) 
[info]     And a compiler should detect this as invalid 
[info]   Scenario: User provides empty projections list
[info]     Given a mapping configuration with no projections 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed with empty projections 
[info]   Scenario: User provides mapping with only optional fields
[info]     Given a minimal mapping configuration 
[info]     When the user compiles the mapping 
[info]     Then the compilation should succeed 
[info]     And optional fields should have None values in plan 
[info]   Scenario: User configures epoch variable in source path
[info]     Given a source configuration with epoch variable 
[info]     When the epoch pattern is examined 
[info]     Then it should contain the epoch placeholder 
[info]     And it should be ready for substitution at runtime 
[debug]     Produced 0 nested tasks and 33 events.
[info] Run completed in 838 milliseconds.
[info] Total number of tests run: 33
[info] Suites: completed 1, aborted 0
[info] Tests: succeeded 33, failed 0, canceled 0, ignored 0, pending 0
[info] All tests passed.
[debug] Passed tests:
[debug] 	cdme.UATSpec
