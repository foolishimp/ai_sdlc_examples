# ADR-001: Sealed ADT Type System

**Status**: Accepted
**Date**: 2026-02-23
**Implements**: REQ-TYP-01, REQ-TYP-02, REQ-TYP-07, REQ-TYP-05

## Context

The CDME specification defines a rich type system (REQ-TYP-01) with primitives, sum types, product types, refinement types (REQ-TYP-02), and optional semantic types (REQ-TYP-07). The type system must support:

1. Exhaustive enumeration of all type variants for pattern matching during type unification (REQ-TYP-06)
2. Structural equality for type comparison
3. Composability (types nest: `Option[List[SemanticType[Int, "Money"]]]`)
4. Compile-time safety — forgetting a type variant in a match expression must produce a compiler warning
5. No implicit coercion between types (REQ-TYP-05)

We need a Scala encoding that satisfies all five requirements while remaining compatible with Scala 2.13.

## Decision

Use **sealed trait hierarchies with case classes** (Algebraic Data Types) to encode the CDME type system.

The root type is `sealed trait CdmeType`. Every variant is a `case class` or `case object` extending `CdmeType`. The `sealed` modifier restricts all subtypes to the same compilation unit, enabling:

- **Exhaustive pattern matching**: The Scala 2.13 compiler emits warnings for non-exhaustive matches on sealed traits. This ensures that every type unification path, every Spark type mapping, and every serialization handler covers all variants.
- **Structural equality**: Case classes provide `equals`, `hashCode`, and `copy` for free.
- **Immutability**: Case class fields are `val` by default.

### Type Hierarchy

```scala
sealed trait CdmeType

// Primitives (6 variants)
case object IntType       extends CdmeType
case object FloatType     extends CdmeType
case object StringType    extends CdmeType
case object BooleanType   extends CdmeType
case object DateType      extends CdmeType
case object TimestampType extends CdmeType

// Composite types (4 variants)
final case class OptionType(inner: CdmeType)                extends CdmeType
final case class ListType(element: CdmeType)                extends CdmeType
final case class ProductType(fields: Map[String, CdmeType]) extends CdmeType
final case class SumType(variants: Map[String, CdmeType])   extends CdmeType

// Extended types (2 variants)
final case class RefinementType(base: CdmeType, predicateName: String, predicateExpr: String)
    extends CdmeType
final case class SemanticType(base: CdmeType, semanticLabel: String)
    extends CdmeType
```

### Why Not Scala 3 Enums

Scala 3 provides `enum` syntax with exhaustive matching. However, Scala 3 is not compatible with Spark 3.5 (see ADR-013). The sealed trait encoding in Scala 2.13 achieves the same exhaustiveness guarantees via `-Xlint:_` and `-Wconf` compiler flags.

## Consequences

### Positive

- The Scala compiler enforces exhaustive matching at compile time, catching missing type variants early
- Structural equality simplifies type comparison in the `TypeUnifier`
- Case classes are immutable by default, aligning with the functional paradigm constraint
- Types compose naturally via nesting
- Pattern matching in `TypeUnifier.unify` is clean and readable
- JSON/YAML serialization is straightforward via standard libraries

### Negative

- Adding a new type variant requires modifying the sealed hierarchy file and updating all match expressions across the codebase
- Scala 2.13 exhaustiveness warnings are advisory (not errors by default); the build must enable `-Xfatal-warnings` to make them hard errors
- No built-in schema evolution story for the type hierarchy (adding a variant is a breaking change)

### Risks

- If a future requirement adds many domain-specific types (e.g., 50 semantic types), the flat hierarchy may become unwieldy. Mitigation: semantic types are parameterized by label string, not enumerated as case classes.
- Performance of deeply nested type matching (e.g., `OptionType(ListType(ProductType(...)))`) is linear in nesting depth. Unlikely to be a bottleneck for reasonable type depths.

## Alternatives Considered

1. **Tagless final encoding** — More flexible but harder to serialize, debug, and explain to data architects. Rejected for pragmatic reasons.
2. **Runtime type descriptors (stringly-typed)** — Loses compile-time safety entirely. Rejected as incompatible with REQ-TYP-05 and REQ-AI-01.
3. **Scala 3 enums** — Better syntax but incompatible with Spark 3.5. See ADR-013.

## References

- [ADR-013](ADR-013.md) — Scala 2.13 over Scala 3 (Spark compatibility)
- [ADR-003](ADR-003.md) — Either-Based Error Handling (errors from type violations)
- [ADR-006](ADR-006.md) — Spark Integration Strategy (CdmeType to Spark type mapping)
- REQ-TYP-01 — Extended Type System
- REQ-TYP-02 — Refinement Types
- REQ-TYP-05 — No Implicit Casting
- REQ-TYP-06 — Type Unification Rules
- REQ-TYP-07 — Semantic Type Enforcement
