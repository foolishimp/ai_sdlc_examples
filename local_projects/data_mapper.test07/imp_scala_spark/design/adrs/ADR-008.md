# ADR-008: Testing Strategy

**Status**: Accepted
**Date**: 2026-02-23
**Implements**: REQ-TYP-04, REQ-TRV-05, REQ-LDM-04

## Context

The CDME provides mathematical guarantees: topological correctness, grain safety, type enforcement, and deterministic reproducibility (REQ-TRV-05). These guarantees must be verified through testing.

The specification requires:
- Idempotency of failure: re-processing same inputs produces same errors (REQ-TYP-04)
- Deterministic reproducibility: same inputs + same config = same outputs (REQ-TRV-05)
- Monoid law compliance: associativity and identity for all aggregation functions (REQ-LDM-04)
- Adjoint containment laws: `backward(forward(x)) supseteq x` for all adjoint pairs
- Accounting invariant: `|input| = |processed| + |filtered| + |errored|` for every run

These properties are **universal quantifications** — they must hold for all inputs, not just specific test cases. This makes them ideal candidates for property-based testing.

## Decision

Use **ScalaTest** as the primary test framework and **ScalaCheck** for property-based testing of algebraic invariants.

### Testing Stack

| Library | Version | Purpose |
|---------|---------|---------|
| ScalaTest | 3.2.18 | Unit tests, integration tests, BDD-style specs |
| ScalaCheck | 1.17.0 | Property-based tests for algebraic laws |
| scalacheck-shapeless (optional) | 1.3.1 | Automatic `Arbitrary` derivation for case classes |
| spark-testing-base (optional) | 0.14.0 | SharedSparkContext for Spark integration tests |

### Test Categories

#### 1. Unit Tests (ScalaTest FlatSpec/WordSpec)

Per-module tests verifying individual components in isolation.

- **cdme-model**: Type construction, grain comparison, adjoint classification equality
- **cdme-compiler**: Path verification, grain checking, type unification, cost estimation
- **cdme-runtime**: Error routing, circuit breaker, accounting ledger construction
- **cdme-adjoint**: Adjoint composition, reconciliation, impact analysis

#### 2. Property-Based Tests (ScalaCheck)

Algebraic invariants verified with random inputs:

```scala
// Monoid law: associativity
property("sum monoid is associative") = forAll { (a: Long, b: Long, c: Long) =>
  SumMonoid.combine(SumMonoid.combine(a, b), c) ==
    SumMonoid.combine(a, SumMonoid.combine(b, c))
}

// Monoid law: identity
property("sum monoid has identity") = forAll { (a: Long) =>
  SumMonoid.combine(a, SumMonoid.identity) == a
}

// Adjoint containment law
property("aggregation adjoint satisfies containment") = forAll { (records: Set[Record]) =>
  val forward = aggAdjoint.forward(records)
  val backward = aggAdjoint.backward(forward)
  records.subsetOf(backward)  // backward(forward(x)) supseteq x
}

// Deterministic reproducibility
property("execution is deterministic") = forAll { (input: ValidInput) =>
  val result1 = runtime.execute(plan, context, input)
  val result2 = runtime.execute(plan, context, input)
  result1 == result2
}

// Type unification symmetry (when both sides equal)
property("type unification with self succeeds") = forAll { (t: CdmeType) =>
  typeUnifier.unify(t, t, SubtypeRegistry.empty).isRight
}
```

#### 3. Integration Tests (ScalaTest + Spark)

End-to-end tests using real Spark sessions:

- Full pipeline: LDM -> compile -> execute -> verify accounting invariant
- Skew mitigation: salted joins produce correct results
- Error routing: circuit breaker trips at threshold
- OpenLineage: events emitted with correct facets

#### 4. Contract Tests

Tests that verify cross-module contracts:

- Compiler produces plans that the runtime can execute
- Spark type mapping round-trips correctly (CdmeType -> StructType -> CdmeType)
- Adjoint metadata is sufficient for backward traversal

### Test Organization

```
cdme-model/src/test/scala/com/cdme/model/
  +-- TypeSpec.scala          (unit: type construction, equality)
  +-- TypeLawsSpec.scala      (property: type algebra properties)
  +-- GrainOrderingSpec.scala (property: total order laws)

cdme-compiler/src/test/scala/com/cdme/compiler/
  +-- PathVerifierSpec.scala   (unit: valid/invalid paths)
  +-- GrainCheckerSpec.scala   (unit: grain violation detection)
  +-- TypeUnifierSpec.scala    (unit + property: unification rules)
  +-- CostEstimatorSpec.scala  (unit: budget checks)

cdme-runtime/src/test/scala/com/cdme/runtime/
  +-- ErrorRouterSpec.scala        (unit: bifurcation, circuit breaker)
  +-- AccountingVerifierSpec.scala (property: invariant holds)
  +-- MorphismExecutorSpec.scala   (unit: Kleisli lift, monoid fold)

cdme-adjoint/src/test/scala/com/cdme/adjoint/
  +-- AdjointLawsSpec.scala        (property: containment laws)
  +-- AdjointComposerSpec.scala    (property: contravariant composition)
  +-- ReconciliationSpec.scala     (unit: reconciliation engine)

cdme-spark/src/test/scala/com/cdme/spark/
  +-- TypeMappingSpec.scala        (unit: CdmeType <-> StructType)
  +-- SparkExecutionSpec.scala     (integration: full pipeline)
  +-- SkewMitigatorSpec.scala      (integration: salted joins)
```

### Custom ScalaCheck Generators

```scala
// Generator for valid CdmeType instances
implicit val arbCdmeType: Arbitrary[CdmeType] = Arbitrary(Gen.oneOf(
  Gen.const(IntType),
  Gen.const(FloatType),
  Gen.const(StringType),
  Gen.const(BooleanType),
  Gen.const(DateType),
  Gen.const(TimestampType),
  arbCdmeType.arbitrary.map(OptionType),
  arbCdmeType.arbitrary.map(ListType)
  // Recursive generators bounded by size
))
```

## Consequences

### Positive

- Property-based tests catch edge cases that hand-written unit tests miss
- Algebraic laws (monoid, adjoint, determinism) are tested universally, not just for examples
- ScalaTest + ScalaCheck is a well-established Scala testing combination
- Per-module test isolation means fast feedback loops (model tests run without Spark)
- Integration tests verify end-to-end correctness with real Spark execution

### Negative

- Property-based tests are slower than unit tests (generating and checking many inputs)
- ScalaCheck generators for complex types (nested ADTs) can be tricky to write correctly
- Spark integration tests require a SparkSession, which is slow to start (~5 seconds)
- Maintaining custom Arbitrary instances adds test infrastructure code

### Risks

- Flaky property tests if generators produce degenerate inputs (e.g., extremely deep nesting, empty collections). Mitigation: configure generator size bounds and add `whenever` guards.
- Spark integration tests may be brittle across Spark minor versions. Mitigation: pin Spark version.

## Alternatives Considered

1. **Only unit tests (no ScalaCheck)** — Faster but misses the universal invariants. Rejected because algebraic properties are the core value proposition of CDME.
2. **Specs2** — Alternative Scala test framework with property support. Less widely adopted than ScalaTest. Rejected for ecosystem reasons.
3. **Hedgehog-Scala** — Alternative property testing library with integrated shrinking. Less mature than ScalaCheck. Rejected.
4. **Formal verification (e.g., Stainless)** — Would provide mathematical proof but is impractical for the full codebase. Considered for critical paths (type unification, grain checking) in future.

## References

- [ADR-001](ADR-001.md) — Sealed ADT Type System (type generators)
- [ADR-002](ADR-002.md) — Category Representation (category generators)
- [ADR-003](ADR-003.md) — Either-Based Error Handling (error path testing)
- [ADR-004](ADR-004.md) — Adjoint Morphism Design (containment law tests)
- [ADR-005](ADR-005.md) — Grain Ordering System (order law tests)
- [ADR-007](ADR-007.md) — Multi-Module sbt Structure (per-module test isolation)
- REQ-TYP-04 — Idempotency of Failure
- REQ-TRV-05 — Deterministic Reproducibility
- REQ-LDM-04 — Algebraic Aggregation (Monoid Laws)
- REQ-ADJ-01 — Adjoint Interface Structure (containment laws)
